{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Агент ReAct с нуля с Gemini 2.5 и LangGraph\n",
    "\n",
    "Приложения ИИ развиваются от простых чат-ботов до (полу)автономных систем, способных к сложному рассуждению, планированию и взаимодействию с реальным миром. Мы называем эти системные агенты. \n",
    "\n",
    "> Агент ИИ — это система, которая использует LLM для определения потока управления приложением.\n",
    "\n",
    "\n",
    "Агенты — это не просто теоретические концепции; они есть и будут развертываться в производстве в различных вертикалях, решая все более сложные и длительные задачи. В этом сообщении в блоге мы рассмотрим, как создать агент ReAct с помощью Google Gemini 2.5 Pro или Gemini 2.0 Flash и LangGraph с нуля. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такое агенты ReAct?\n",
    "\n",
    "Агенты ReAct (Reasoning and Acting) — это системы ИИ, которые сочетают в себе возможности рассуждения LLM с выполнением действий, что позволяет им итеративно обдумывать проблемы, использовать инструменты и действовать на основе наблюдений для достижения целей пользователя.\n",
    "\n",
    "Шаблон ReAct был впервые представлен в [\"ReAct: синергия рассуждений и действий в языковых моделях\"](https://arxiv.org/abs/2210.03629) в 2023 году. Он был вдохновлен тем, как люди планируют и решают сложные задачи, а не реализуют предопределенные рабочие процессы. Агенты ReAct полагаются на возможности рассуждения LLM для динамической корректировки своих действий на основе новой информации или результатов предыдущих шагов. \n",
    "\n",
    "Агенты ReAct приобрели популярность благодаря своей способности решать сложные задачи, разбивая их на управляемые этапы рассуждений и используя внешние инструменты. \n",
    "\n",
    "![react.png](../assets/react.png)\n",
    "\n",
    "Агент ReAct:\n",
    "\n",
    "1. Принимает **запрос** пользователя в качестве входных данных\n",
    "2. Рассуждает о запросе и принимает решение о действии \n",
    "3. Выполняет выбранное действие с помощью доступных инструментов\n",
    "4. Наблюдает за результатом действия\n",
    "5. Повторяет шаги 2-4, пока не сможет дать окончательный ответ\n",
    "\n",
    "### Первые агенты ReAct\n",
    "\n",
    "Эти агенты ReAct первого поколения использовали простую, но эффективную технику подсказок для создания цепочки шагов «Мысль, действие, наблюдение»:\n",
    "\n",
    "- Компонент «Мысль» планирует следующее действие или решает, что знает окончательный ответ\n",
    "- «Действие» взаимодействует с внешними ресурсами (например, поисковыми системами или калькуляторами).\n",
    "- «Наблюдение» включает результаты действия в процесс рассуждения.\n",
    "\n",
    " Вот пример псевдокода, демонстрирующий поток раннего агента ReAct. \n",
    "\n",
    "```xml\n",
    "Пользователь: Кто парень Оливии Уайлд? Какой его текущий возраст, возведенный в степень 0,23?\n",
    "\n",
    "Мысль: Мне нужно выяснить, кто парень Оливии Уайлд, а затем вычислить его возраст, возведенный в степень 0,23.\n",
    "Действие: [поиск(\"парень Оливии Уайлд\")]\n",
    "Наблюдение: Оливия Уайлд начала встречаться с Гарри Стайлсом после прекращения многолетней помолвки с Джейсоном Судейкисом — см. их хронологию отношений.\n",
    "\n",
    "Мысль: Мне нужно узнать возраст Гарри Стайлса.\n",
    "Действие: [поиск(\"возраст Гарри Стайлса\")]\n",
    "Наблюдение: 29 лет\n",
    "\n",
    "Мысль: Мне нужно вычислить 29 в степени 0,23.\n",
    "Действие: [калькулятор(29^0.23)]\n",
    "Наблюдение: Ответ: 2.169459462491557\n",
    " \n",
    "Мысль: Теперь я знаю окончательный ответ.\n",
    "Окончательный ответ: Гарри Стайлсу, парню Оливии Уайлд, 29 лет, и его возраст, возведенный в степень 0,23, равен 2.169459462491557.\n",
    "```\n",
    "\n",
    "### Текущие агенты ReAct\n",
    "\n",
    "С момента появления агента ReAct возможности LLM эволюционировали. Одним из наиболее важных улучшений, которые мы сделали, является вызов функций. Вызов функций позволяет нам подключать LLM к внешним инструментам структурированным образом, что более надежно, чем синтаксический анализ необработанного текста, и снижает вероятность ошибок и галлюцинаций.\n",
    "\n",
    "Вот пример псевдокода, демонстрирующий поток агента ReAct с использованием вызова функций \n",
    "\n",
    "```xml\n",
    "Пользователь: Кто парень Оливии Уайлд? Какой его текущий возраст, возведенный в степень 0,23?\n",
    "\n",
    "Ассистент: FunctionCall(name=\"search\", args={"query": \"парень Оливии Уайлд\"})\n",
    "Пользователь: FunctionResponse(result=\"Оливия Уайлд начала встречаться с Гарри Стайлсом после прекращения многолетней помолвки с Джейсоном Судейкисом — см. их хронологию отношений.\")\n",
    "\n",
    "Ассистент: FunctionCall(name=\"search\", args={"query": \"возраст Гарри Стайлса\"})\n",
    "Пользователь: FunctionResponse(result=\"29 лет\")\n",
    "\n",
    "Ассистент: FunctionCall(name=\"calculator\", args={"expression": \"29^0.23\"})\n",
    "Пользователь: FunctionResponse(result=\"2.169459462491557\")\n",
    "\n",
    "Ассистент: Гарри Стайлсу, парню Оливии Уайлд, 29 лет. Его возраст, возведенный в степень 0,23, равен 2.169459462491557.\n",
    "```\n",
    "\n",
    "### Традиционные агенты ReAct и текущие агенты ReAct (вызов функций)\n",
    "\n",
    "| **Аспект** | **Традиционные агенты ReAct** | **Текущие агенты ReAct (вызов функций)** |\n",
    "| --- | --- | --- |\n",
    "| Действия | Текстовое описание, анализируемое системой | Прямые вызовы функций в структурированном формате |\n",
    "| Эффективность | Ниже из-за ошибок синтаксического анализа | Выше, с уменьшенными накладными расходами на синтаксический анализ |\n",
    "| Надежность | Более подвержены ошибкам и галлюцинациям | Более надежное и точное выполнение инструментов |\n",
    "| Требования к LLM | Работает с любым LLM | Требуются LLM, поддерживающие вызов функций |\n",
    "| Реализация | В основном за счет тщательной разработки подсказок | Часто облегчается с помощью SDK и фреймворков, таких как LangGraph |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как создать агент ReAct с нуля с помощью LangGraph\n",
    "\n",
    "Мы знаем, как работают агенты ReAct. Теперь давайте создадим свой собственный с нуля. Мы будем использовать LangGraph и Gemini 2.5 Pro. LangGraph — это фреймворк для создания управляемых агентов. LangGraph уже поставляется с готовым агентом ReAct [create_react_agent](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent), но иногда вам может потребоваться больше контроля и настройки. \n",
    "Кроме того, полезно понимать основные концепции и то, как создать собственный агент ReAct с нуля.\n",
    "\n",
    "Агенты моделей LangGraph в виде графов. Вы определяете поведение агентов с помощью трех ключевых компонентов:\n",
    "- `State`: общая структура данных, которая представляет текущий снимок вашего приложения. Это может быть любой тип Python, но обычно это TypedDict или Pydantic BaseModel, который является общим для всех узлов.\n",
    "- `Nodes`: кодирует логику ваших агентов. Они получают текущее состояние в качестве входных данных, выполняют некоторые вычисления или побочные эффекты и возвращают обновленное состояние, например, вызовы LLM, вызовы инструментов и т. д.\n",
    "- `Edges`: определяют, какой узел выполнять следующим, на основе текущего состояния. Это могут быть условные ветви или фиксированные переходы.\n",
    "\n",
    "Сначала мы установили необходимые пакеты и установили наши ключи API. Если у вас еще нет ключа API, вы можете получить его бесплатно в [Google AI Studio](https://aistudio.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langgraph langchain-google-genai geopy requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Прочтите свой ключ API из переменной окружения или установите его вручную\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\",\"xxx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы собираемся создать самых простых агентов ReAct, которые используют смоделированный 1 инструмент для получения погоды для данного местоположения. Для этого нам нужно хранить историю разговоров в виде списка сообщений в состоянии нашего графа. Мы будем использовать вспомогательную функцию [add_messages](https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages) для добавления сообщений в состояние. Функция `add_messages` — это [редуктор](https://langchain-ai.github.io/langgraph/concepts/low_level/#reducers), который объединяет два списка сообщений, обновляя существующие сообщения по идентификатору и гарантируя, что состояние является \"только для добавления\", если только новое сообщение не имеет того же идентификатора, что и существующее сообщение. В демонстрационных целях мы также храним количество шагов в состоянии. \n",
    "\n",
    "Примечание: поскольку наличие списка сообщений в состоянии является очень распространенным явлением, существует предварительно созданное состояние под названием `MessagesState`, которое упрощает использование сообщений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated,Sequence, TypedDict\n",
    "\n",
    "from langchain_core.messages import BaseMessage \n",
    "from langgraph.graph.message import add_messages # вспомогательная функция для добавления сообщений в состояние\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"Состояние агента.\"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    number_of_steps: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы определяем наш инструмент погоды.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from geopy.geocoders import Nominatim\n",
    "from pydantic import BaseModel, Field\n",
    "import requests\n",
    "\n",
    "geolocator = Nominatim(user_agent=\"weather-app\") \n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    location:str = Field(description=\"Город и штат, например, Сан-Франциско\")\n",
    "    date:str = Field(description=\"дата прогноза, на которую нужно получить погоду в формате (гггг-мм-дд)\")\n",
    "\n",
    "@tool(\"get_weather_forecast\", args_schema=SearchInput, return_direct=True)\n",
    "def get_weather_forecast(location: str, date: str):\n",
    "    \"\"\"Получает погоду с помощью API Open-Meteo для заданного местоположения (города) и даты (гггг-мм-дд). Возвращает список словарей со временем и температурой для каждого часа.\"\"\"\n",
    "    location = geolocator.geocode(location)\n",
    "    if location:\n",
    "        try:\n",
    "            response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={location.latitude}&longitude={location.longitude}&hourly=temperature_2m&start_date={date}&end_date={date}\")\n",
    "            data = response.json()\n",
    "            return {time: temp for time, temp in zip(data[\"hourly\"][\"time\"], data[\"hourly\"][\"temperature_2m\"])}\n",
    "        except Exception as e:\n",
    "            return {\"error\": str(e)}\n",
    "    else:\n",
    "        return {\"error\": \"Местоположение не найдено\"}\n",
    "\n",
    "tools = [get_weather_forecast]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы инициализируем нашу модель и привязываем инструменты к модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_weather_forecast', 'arguments': '{\"date\": \"2025-03-12\", \"location\": \"Berlin\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-44df877a-9f22-463a-833d-889f9ee8ea52-0', tool_calls=[{'name': 'get_weather_forecast', 'args': {'date': '2025-03-12', 'location': 'Berlin'}, 'id': 'c0994e14-dfd9-4718-8c59-74f804dd5896', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 31, 'total_tokens': 163, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "  \n",
    "# Создать класс LLM \n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model= \"gemini-2.5-pro-exp-03-25\", # замените на \"gemini-2.0-flash\"\n",
    "    temperature=1.0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    google_api_key=api_key,\n",
    ")\n",
    "\n",
    "# Привязать инструменты к модели\n",
    "model = llm.bind_tools([get_weather_forecast])\n",
    "\n",
    "# Протестировать модель с инструментами\n",
    "model.invoke(\"Какая погода в Берлине 12 марта 2025 года?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последний шаг перед тем, как мы сможем запустить нашего агента, — это определить наши узлы и ребра. В наших примерах у нас есть два узла и 1 ребро.\n",
    "- Узел `call_tool`, который выполняет наш метод инструмента. В LangGraph для этого есть готовый узел под названием [ToolNode](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/).\n",
    "- Узел `call_model`, который использует `model_with_tools` для вызова модели. \n",
    "- Ребро `should_continue`, которое решает, вызывать ли инструмент или модель.\n",
    "\n",
    "Количество узлов и ребер не является фиксированным. Вы можете добавлять в свой граф столько узлов и ребер, сколько захотите. Например, вы можете добавить узел для добавления структурированного вывода или узел самопроверки/размышления для проверки вывода модели перед вызовом инструмента или модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "# это похоже на настройку create_react_agent с параметром 'prompt', но более гибко\n",
    "# system_prompt = SystemMessage(\n",
    "#     \"Вы — полезный помощник, который использует инструменты для доступа и получения информации из API погоды. Сегодня 4 марта 2025 года. Помогите пользователю с его вопросами. Используйте историю, чтобы ответить на вопрос.\"\n",
    "# )\n",
    "\n",
    "# Определите наш узел инструмента\n",
    "def call_tool(state: AgentState):\n",
    "    outputs = []\n",
    "    # Итерация по вызовам инструментов в последнем сообщении\n",
    "    for tool_call in state[\"messages\"][-1].tool_calls:\n",
    "        # Получить инструмент по имени\n",
    "        tool_result = tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "        outputs.append(\n",
    "            ToolMessage(\n",
    "                content=tool_result,\n",
    "                name=tool_call[\"name\"],\n",
    "                tool_call_id=tool_call[\"id\"],\n",
    "            )\n",
    "        )\n",
    "    return {\"messages\": outputs}\n",
    "\n",
    "def call_model(\n",
    "    state: AgentState,\n",
    "    config: RunnableConfig,\n",
    "):\n",
    "    # Вызвать модель с системной подсказкой и сообщениями\n",
    "    response = model.invoke(state[\"messages\"], config)\n",
    "    # Мы возвращаем список, потому что он будет добавлен к существующему состоянию сообщений с помощью редуктора add_messages\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Определите условное ребро, которое определяет, продолжать или нет\n",
    "def should_continue(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    # Если последнее сообщение не является вызовом инструмента, то мы заканчиваем\n",
    "    if not messages[-1].tool_calls:\n",
    "        return \"end\"\n",
    "    # по умолчанию продолжить\n",
    "    return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, теперь у нас есть все компоненты для создания нашего агента. Давайте соберем их вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "# Определите новый граф с нашим состоянием\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# 1. Добавьте наши узлы \n",
    "workflow.add_node(\"llm\", call_model)\n",
    "workflow.add_node(\"tools\",  call_tool)\n",
    "# 2. Установите точку входа как `agent`, это первый вызываемый узел\n",
    "workflow.set_entry_point(\"llm\")\n",
    "# 3. Добавьте условное ребро после вызова узла `llm`.\n",
    "workflow.add_conditional_edges(\n",
    "    # Ребро используется после вызова узла `llm`.\n",
    "    \"llm\",\n",
    "    # Функция, которая будет определять, какой узел будет вызван следующим.\n",
    "    should_continue,\n",
    "    # Сопоставление, куда идти дальше, ключи — это строки из возвращаемого значения функции, а значения — другие узлы.\n",
    "    # END — это специальный узел, отмечающий, что граф завершен.\n",
    "    {\n",
    "        # Если `tools`, то мы вызываем узел инструмента.\n",
    "        \"continue\": \"tools\",\n",
    "        # В противном случае мы заканчиваем.\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "# 4. Добавьте обычное ребро после вызова `tools`, следующим вызывается узел `llm`.\n",
    "workflow.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "# Теперь мы можем скомпилировать и визуализировать наш граф\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем визуализировать наш граф с помощью метода `draw_mermaid_png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPYAAAERCAIAAADHRs0RAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdYVFce98/0PsPQh14EAUERbLFEExQVe8u6lpU16lqSaBIxBvU1ZteQZo36rgkqiWjsRiMGjSSamJjEGgUEBEHqMAxtep/3j7vvSHRAhDtz7lzO58mTB24558vcr2d+95TfoVitVoBAkBcqbAEIhGNBFkeQHGRxBMlBFkeQHGRxBMlBFkeQHDpsAXCQVug1CpNaYTKbrHqtBbacZ8NkU2l0Ck9I4wkZPiEsCgW2INeB0qP6xYtuKMvvqR7mq0NjeIACeEK62IfhEhZncWjNMoNGYTLorVUlmpBobmgsP2aIEHn9mfQUi9+72vp7bmNwNC8slhcax6e6eIBWUaAuz1c/uq+JGyFKTBLDlkNoyG9xWZX+u6y6kBje0EmeDCbZGr1fv23M/7V13ALfoCgubC0EheQWL/xdce9q64RXJXw30r516LWWvCMy32BWwsuoObcDmS1e9qeq4r4mabY3bCHO4Jezcr4bvd+LbrCFEA7SWvz6xaYWmXHMPB/YQpzHz9/ILWbryBlesIUQCxd/7WqH8ny1rFLfo/wNABgx1dNithZcU8AWQixIaHFFo+n+H4oJiySwhUDgpVe868q19Y/0sIUQCBJa/Oo3DVEDhbBVQCN2qOin0w2wVRAIsllcWqFTK81hcTzYQqDhG8LmCWgP76lhCyEKZLN44TXFiKk9/X1r+FTP4ptK2CqIAqksrtNYyvJVviEsZ1Z67Nix9957rws3vvPOO99++60DFAGhB6NJqm+uNziicJeDVBYvv6cKi+U7udL79+87+cbOENqH/zAfxSqAbP3iPxyV9erHd9BQ9u3bt3fv3l1aWmo2myMjI1esWJGQkLBkyZJbt25hFxw6dKh37965ubkHDx6srKxkMpl9+/Z9++23AwICsDabQqGEhIRkZ2dnZGS8+eab2F18Pv/y5cu4q62v1N/+sXncAl/cS3Y5SNWK15VrBWKHDNRrtdpVq1aFhYUdOHDgyy+/jIiIeOONNxQKxdatW6OiopKTky9dutSrV6+CgoL169cPGzbs4MGDO3fu1Gq1aWlpWAkMBqO0tLSoqGjnzp1xcXHnz58HAKSlpZ05c8YRgoXu9OoHWkeU7HKQauaGRmHmChzyF0mlUrVanZKSEhoaCgBYvXr1mDFjmEwmm82m0+lMJtPNzQ0AEBwcfPDgwYiICDqdDgCYM2fOW2+91dTU5O7uDgCorq7et2+fSCQCAOj1egAAl8vFfsUdDp+m15otFuDqcyq7D3ksbjFbjQYLi+uQRxoUFBQcHLx+/fqZM2cOGTKkd+/eiYmJT1/G5/Nramp27dpVVVWl0+mMRiMAQKFQYBYPDg52kKHtwhPSNQoTieefdRLy/Bu3mAGH76jHSaPRMjMzR48effr06Xnz5k2aNCknJ+fpyy5evLh27drY2NidO3cePnx43bp1bc/y+U59FWZzqRazMyskKOSxOJ1JMegsBp2jlvCIxeJVq1adOXPm2LFjgwYN2rhx49NdIqdPnx4wYMCyZctCQkI8PT11Op2DxHSGZpmRJ6RBFEAQyGNxAABXQNMoHdJw1dTU2Po9wsLC0tPTqVRqWVkZdsTWK2UwGLCgHCM3N7ft2adxXHeWXmuh0Sk0BtmWgHQBUlncvxdHq3KIxaVS6Zo1a7KzsysqKh49epSZmUmlUuPi4gAAAoGguLi4uLi4paUlNjb2t99+y8/Pr6ury8jI8PT0BAAUFhY+3ZyzWCwWi3Xr1q3i4mKTyYS7YE2rORitAwIAAEDr2sgcMVE0GuvKdcHR+D9aPz8/Pz+/kydPZmVlnTlzRqPRrF27tm/fvgAAkUiUk5Nz6tSp/v37JycnP3jw4PPPPz9//nxiYuKbb7559+7do0ePhoSEVFZWqlSqKVOm2Mq0WCynT5++cOHC... [truncated]