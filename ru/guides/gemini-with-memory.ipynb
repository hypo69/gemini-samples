{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интеграция долговременной памяти с Gemini 2.5\n",
    "\n",
    "По умолчанию большие языковые модели (LLM) не имеют состояния, что означает, что они не запоминают прошлые разговоры. Это может затруднить создание действительно личных и полезных приложений ИИ. В этом руководстве показано, как добавить долговременную память в чат-бот Gemini 2.5 с помощью Gemini API и [Mem0](https://github.com/mem0ai/mem0). \n",
    "\n",
    "Добавив систему памяти, ваш чат-бот сможет:\n",
    "\n",
    "*   Запоминать детали о пользователе из прошлых разговоров.\n",
    "*   Давать более релевантные и личные ответы.\n",
    "*   Перестать задавать одни и те же вопросы снова и снова.\n",
    "\n",
    "В этом примере мы будем использовать `mem0`, инструмент с открытым исходным кодом для предоставления агентам ИИ долговременной памяти, и Gemini 2.5 Flash в качестве LLM. Мы создадим простого чат-бота, который сохраняет то, о чем вы говорите, и использует эту историю, чтобы давать вам лучшие, более персонализированные ответы.\n",
    "\n",
    "## Как работает Mem0?\n",
    "\n",
    "Mem0 предназначен для оснащения агентов ИИ масштабируемой долговременной памятью, эффективно устраняя ограничения фиксированных окон контекста в LLM. По своей сути mem0 работает путем реактивного извлечения, консолидации и извлечения важной информации из текущих разговоров.\n",
    "\n",
    "Процесс разделен на четыре этапа:\n",
    "\n",
    "1. Извлечение важной информации из разговоров с использованием LLM с двойным контекстом (краткое изложение разговора в сочетании с последними сообщениями).\n",
    "2. Использование LLM для обработки контекста и извлечения важной новой информации и сравнения ее с существующей с использованием семантического сходства.\n",
    "3. Обновление памяти (ADD, UPDATE, DELETE или NOOP), для варианта Mem0g (граф), извлечение сущностей и отношений.\n",
    "4. Использование поиска по векторному сходству для извлечения релевантных воспоминаний для генерации ответа.\n",
    " \n",
    "Он использует векторные вложения для хранения и извлечения семантической информации, поддерживая контекст, специфичный для пользователя, в разных сеансах и реализуя эффективные механизмы извлечения для релевантных прошлых взаимодействий.\n",
    "\n",
    "## Настройка\n",
    "\n",
    "Для начала нам нужно установить библиотеку Mem0 и клиент Gemini API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install google-genai mem0ai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    