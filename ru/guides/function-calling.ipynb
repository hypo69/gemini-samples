# Вызов функций с помощью Google DeepMind Gemini 2.0 Flash

Вызов функций — это возможность подключать LLM к внешним инструментам и взаимодействовать с вашим кодом и API структурированным образом. Вместо того, чтобы генерировать текстовые ответы, LLM понимают, когда вызывать определенные функции, и предоставляют необходимые параметры для выполнения действий в реальном мире.

В этом руководстве мы рассмотрим практического помощника на основе погоды, имеющего доступ к погодному API. Да, не очень креативно, но есть бесплатный API, который мы можем использовать, и этого должно быть достаточно, чтобы продемонстрировать концепцию и понять, как вы можете использовать вызов функций для создания более сложного помощника.  

Это руководство охватывает: 

1. [Как работает вызов функций?](#how-does-function-calling-work)
2. [Когда использовать вызов функций?](#when-to-use-function-calling)
3. [Вызов функций с помощью Google Gemini 2.0 Flash](#function-calling-with-google-gemini-20-flash)
4. [Дополнительно: вызов функций с помощью LangChain](#advanced-function-calling-with-langchain)
5. [Дополнительно: вызов функций с помощью API, совместимого с OpenAI](#advanced-function-calling-with-openai-compatible-api)

## Как работает вызов функций?

Вызов функций может подразумевать, что LLM напрямую выполняет какое-то действие. Это не так! Когда пользователь запрашивает LLM с вызовом функции, модель анализирует ввод и определяет, какая функция будет наиболее подходящей для задачи (это может быть одна или несколько функций). Вместо того, чтобы предоставлять текстовый ответ, модель генерирует структурированный объект JSON, который указывает, какую функцию вызывать и какие параметры необходимы. 

![Function Intro](../assets/function-intro.png)

На практике вызов функций описывает не только процесс генерации структурированного вывода, но и процесс вызова функции и обработки вывода. Поскольку вы не хотите возвращать необработанный вывод функции своему пользователю, вы хотите, чтобы LLM сгенерировал соответствующий ответ на основе истории разговоров.

![Function calling](../assets/function-calling.png)


Практический вызов функций выполняется в следующие этапы:
1. Ваше приложение отправляет запрос в LLM вместе с определениями функций
2. LLM анализирует запрос и решает, отвечать ли напрямую или использовать определенные функции
3. При использовании функций LLM генерирует структурированные аргументы для вызова функции
4. Ваше приложение получает сведения о вызове функции и выполняет фактическую функцию
5. Результаты функции отправляются обратно в LLM
6. LLM предоставляет окончательный ответ, включающий результаты функции

Этот цикл может продолжаться по мере необходимости, что позволяет осуществлять сложные многоэтапные взаимодействия между приложением и LLM. Также возможно, что LLM решит, что ему необходимо вызвать несколько функций одну за другой или параллельно, прежде чем возвращать окончательный ответ пользователю.


## Когда использовать вызов функций?

Вызов функций стал одним из популярных методов создания агентов ИИ. Он может помочь в создании интерфейсов человек-ИИ, которые получают доступ и запрашивают информацию в реальном времени из внешних источников, таких как API, базы данных и базы знаний, предоставляя при этом пользователям интерфейс на естественном языке (текстовый или аудио).

Вызов функций позволяет автоматизировать такие задачи, как планирование встреч, создание счетов-фактур или отправка напоминаний. Примером использования может быть помощник по обслуживанию клиентов, который может использовать вызов функций для беспрепятственного выполнения таких задач, как проверка статуса заказа, обработка возвратов и обновление информации о клиентах — и все это при сохранении естественного потока разговора с пользователем.

Вам больше не нужно создавать приложения, которые требовали сложных форм или нескольких шагов для сбора информации от пользователя. Вместо этого вы можете создать интерфейс на естественном языке, который позволяет пользователю взаимодействовать с приложением в разговорной манере. Или вообще не иметь пользовательского интерфейса и позволить LLM взаимодействовать с миром от вашего имени.

## Вызов функций с помощью Google Gemini 2.0 Flash

Google Gemini 2.0 Flash поддерживает вызов функций через несколько интерфейсов, [совместимую с OpenAPI схему JSON](https://spec.openapis.org/oas/v3.0.3#schema) и определения функций Python с докстрингами. Если вы используете JavaScript/Typescript, вам в настоящее время необходимо использовать интерфейс схемы JSON. Python SDK `google-genai` может автоматически генерировать схему JSON из определений функций Python и докстрингов. Мы рассмотрим оба интерфейса. 

_Примечание: Gemini 2.0 Flash в настоящее время не поддерживает тип `anyOf` в схеме JSON._

Давайте начнем с интерфейса схемы JSON, но перед этим давайте установим библиотеку `google-genai` и убедимся, что у нас есть ключ API Gemini. Если у вас его еще нет, вы можете получить его в [Google AI Studio](https://aistudio.google.com/app/apikey).
```