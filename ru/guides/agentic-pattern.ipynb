{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c29bb52",
   "metadata": {},
   "source": [
    "# От нуля до единицы: изучение агентных паттернов\n",
    "\n",
    "Агенты ИИ. Агентный ИИ. Агентные архитектуры. Агентные рабочие процессы. Агентные паттерны. Агенты повсюду. Но что это такое на самом деле, и как нам создавать надежные и эффективные агентные системы? Хотя термин «агент» используется в широком смысле, ключевой характеристикой является их способность динамически планировать и выполнять задачи, часто используя внешние инструменты и память для достижения сложных целей.\n",
    "\n",
    "Цель этого поста — изучить распространенные шаблоны проектирования. Думайте об этих шаблонах как о чертежах или многоразовых шаблонах для создания приложений ИИ. Их понимание дает ментальную модель для решения сложных проблем и проектирования систем, которые являются масштабируемыми, модульными и адаптируемыми.\n",
    "\n",
    "Мы рассмотрим несколько распространенных шаблонов, различая более структурированные **рабочие процессы** и более динамичные **агентные паттерны**. Рабочие процессы обычно следуют предопределенным путям, в то время как агенты имеют больше автономии в принятии решений о своем курсе действий.\n",
    "\n",
    "**Почему (агентные) паттерны важны?**\n",
    "\n",
    "*   Паттерны обеспечивают структурированный способ мышления и проектирования систем.\n",
    "*   Паттерны позволяют нам создавать и развивать сложность приложений ИИ и адаптироваться к меняющимся требованиям. Модульные конструкции, основанные на шаблонах, легче изменять и расширять.\n",
    "*   Паттерны помогают управлять сложностью координации нескольких агентов, инструментов и рабочих процессов, предлагая проверенные, многоразовые шаблоны. Они продвигают лучшие практики и общее понимание среди разработчиков.\n",
    "\n",
    "**Когда (и когда не) использовать агентов?**\n",
    "\n",
    "Прежде чем углубляться в шаблоны, крайне важно рассмотреть, *когда* агентный подход действительно необходим.\n",
    "\n",
    "*   Всегда ищите самое простое решение в первую очередь. Если вы знаете точные шаги, необходимые для решения проблемы, фиксированный рабочий процесс или даже простой скрипт могут быть более эффективными и надежными, чем агент.\n",
    "*   Агентные системы часто обменивают повышенную задержку и вычислительные затраты на потенциально лучшую производительность при выполнении сложных, неоднозначных или динамических задач. Убедитесь, что преимущества перевешивают эти затраты.\n",
    "*   Используйте **рабочие процессы** для предсказуемости и согласованности при работе с четко определенными задачами, где шаги известны. \n",
    "*   Используйте **агентов**, когда необходимы гибкость, адаптируемость и принятие решений на основе моделей.\n",
    "*   Сохраняйте простоту (все еще): даже при создании агентных систем стремитесь к простейшей эффективной конструкции. Чрезмерно сложные агенты могут стать трудными для отладки и управления.\n",
    "*   Агентность вносит присущую непредсказуемость и потенциальные ошибки. Агентные системы должны включать надежное ведение журнала ошибок, обработку исключений и механизмы повторных попыток, позволяя системе (или базовому LLM) иметь шанс на самокоррекцию.\n",
    "\n",
    "Ниже мы рассмотрим 3 распространенных шаблона рабочих процессов и 4 агентных шаблона. Мы проиллюстрируем каждый из них, используя чистые вызовы API, не полагаясь на конкретные фреймворки, такие как LangChain, LangGraph, LlamaIndex или CrewAI, чтобы сосредоточиться на основных концепциях.\n",
    "\n",
    "## Обзор паттернов\n",
    "\n",
    "Мы рассмотрим следующие паттерны:\n",
    "- [От нуля до единицы: изучение агентных паттернов](#zero-to-one-learning-agentic-patterns)\n",
    "  - [Обзор паттернов](#pattern-overview)\n",
    "  - [Рабочий процесс: цепочка подсказок](#workflow-prompt-chaining)\n",
    "  - [Рабочий процесс: маршрутизация или передача](#workflow-routing-or-handoff)\n",
    "  - [Рабочий процесс: распараллеливание](#workflow-parallelization)\n",
    "  - [Паттерн рефлексии](#reflection-pattern)\n",
    "  - [Паттерн использования инструментов](#tool-use-pattern)\n",
    "  - [Паттерн планирования (оркестратор-работники)](#planning-pattern-orchestrator-workers)\n",
    "  - [Паттерн с несколькими агентами](#multi-agent-pattern)\n",
    "  - [Комбинирование и настройка этих паттернов](#combining-and-customizing-these-patterns)\n",
    "  - [Ресурсы:](#resources)\n",
    "\n",
    "## Рабочий процесс: цепочка подсказок\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<img src=\"../assets/agentic-patterns/prompt-chaining.png\" alt=\"Prompt Chaining\" style=\"max-width: 600px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Вывод одного вызова LLM последовательно передается на вход следующего вызова LLM. Этот шаблон разбивает задачу на фиксированную последовательность шагов. Каждый шаг обрабатывается вызовом LLM, который обрабатывает вывод предыдущего. Он подходит для задач, которые можно четко разбить на предсказуемые, последовательные подзадачи. \n",
    "\n",
    "Случаи использования:\n",
    "*   Создание структурированного документа: LLM 1 создает план, LLM 2 проверяет план на соответствие критериям, LLM 3 пишет контент на основе проверенного плана.\n",
    "*   Многоэтапная обработка данных: извлечение информации, ее преобразование, а затем обобщение.\n",
    "*   Создание информационных бюллетеней на основе отобранных входных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e16aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Резюме: Большие языковые модели — это системы ИИ, обученные на огромных наборах данных для генерации человекоподобного текста, перевода языков, создания контента и предоставления информативных ответов.\n",
      "Перевод: Les grands modèles linguistiques sont des systèmes d'IA entraînés sur des ensembles de données massifs pour générer du texte de type humain, traduire des langues, créer du contenu et fournir des réponses informatives.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# --- Шаг 1: Обобщить текст ---\n",
    "original_text = \"Большие языковые модели — это мощные системы ИИ, обученные на огромных объемах текстовых данных. Они могут генерировать человекоподобный текст, переводить языки, писать различные виды творческого контента и отвечать на ваши вопросы в информативной форме.\"\n",
    "prompt1 = f\"Обобщите следующий текст в одном предложении: {original_text}\"\n",
    "\n",
    "# Используйте client.models.generate_content\n",
    "response1 = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt1\n",
    ")\n",
    "summary = response1.text.strip()\n",
    "print(f\"Резюме: {summary}\")\n",
    "\n",
    "# --- Шаг 2: Перевести резюме ---\n",
    "prompt2 = f\"Переведите следующее резюме на французский, верните только перевод, без другого текста: {summary}\"\n",
    "\n",
    "# Используйте client.models.generate_content\n",
    "response2 = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=prompt2\n",
    ")\n",
    "translation = response2.text.strip()\n",
    "print(f\"Перевод: {translation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e63f7",
   "metadata": {},
   "source": [
    "## Рабочий процесс: маршрутизация\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<img src=\"../assets/agentic-patterns/routing-or-handoff.png\" alt=\"Routing\" style=\"max-width: 300px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Начальный LLM действует как маршрутизатор, классифицируя ввод пользователя и направляя его к наиболее подходящей специализированной задаче или LLM. Этот шаблон реализует разделение ответственности и позволяет оптимизировать отдельные последующие задачи (используя специализированные подсказки, разные модели или определенные инструменты) в изоляции. Он повышает эффективность и потенциально снижает затраты за счет использования меньших моделей для более простых задач. Когда задача маршрутизируется, выбранный агент «берет на себя» ответственность за ее выполнение.\n",
    "\n",
    "Сферы применения:\n",
    "*   Системы поддержки клиентов: маршрутизация запросов к агентам, специализирующимся на выставлении счетов, технической поддержке или информации о продукте.\n",
    "*   Многоуровневое использование LLM: маршрутизация простых запросов к более быстрым и дешевым моделям (например, Llama 3.1 8B) и сложных или необычных вопросов к более способным моделям (например, Gemini 1.5 Pro).\n",
    "*   Генерация контента: маршрутизация запросов на посты в блогах, обновления в социальных сетях или рекламные тексты к различным специализированным подсказкам/моделям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e097897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Решение о маршрутизации: Категория=Category.WEATHER, Обоснование=Запрос касается погодных условий в определенном месте.\n",
      "\n",
      "Окончательный ответ: Хорошо, учитывая, что вопрос «Какая погода в Париже?», прогноз погоды будет для **Парижа, Франция.**\n",
      "\n",
      "Вот краткий прогноз:\n",
      "\n",
      "**Ожидается, что в Париже будет [вставьте сюда реалистичный прогноз, например, переменная облачность с максимумом 22 градуса Цельсия (72 градуса по Фаренгейту) и минимумом 14 градусов Цельсия (57 градусов по Фаренгейту). Днем есть небольшая вероятность дождей].**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from pydantic import BaseModel\n",
    "import enum\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Определите схему маршрутизации\n",
    "class Category(enum.Enum):\n",
    "    WEATHER = \"weather\"\n",
    "    SCIENCE = \"science\"\n",
    "    UNKNOWN = \"unknown\"\n",
    "\n",
    "class RoutingDecision(BaseModel):\n",
    "    category: Category\n",
    "    reasoning: str\n",
    "\n",
    "# Шаг 1: Маршрутизация запроса\n",
    "user_query = \"Какая погода в Париже?\"\n",
    "# user_query = \"Объясните квантовую физику простыми словами.\"\n",
    "# user_query = \"Какая столица Франции?\"\n",
    "\n",
    "prompt_router = f\"\"\"\n",
    "Проанализируйте запрос пользователя ниже и определите его категорию.\n",
    "Категории:\n",
    "- погода: для вопросов о погодных условиях.\n",
    "- наука: для вопросов о науке.\n",
    "- неизвестно: если категория неясна.\n",
    "\n",
    "Запрос: {user_query}\n",
    "\"\"\"\n",
    "\n",
    "# Используйте client.models.generate_content с конфигурацией для структурированного вывода\n",
    "response_router = client.models.generate_content(\n",
    "    model= 'gemini-2.0-flash-lite',\n",
    "    contents=prompt_router,\n",
    "    config={\n",
    "        'response_mime_type': 'application/json',\n",
    "        'response_schema': RoutingDecision,\n",
    "    },\n",
    ")\n",
    "print(f\"Решение о маршрутизации: Категория={response_router.parsed.category}, Обоснование={response_router.parsed.reasoning}\")\n",
    "\n",
    "# Шаг 2: Передача на основе маршрутизации\n",
    "final_response = \"\"\n",
    "if response_router.parsed.category == Category.WEATHER:\n",
    "    weather_prompt = f\"Предоставьте краткий прогноз погоды для местоположения, упомянутого в: '{user_query}'\"\n",
    "    weather_response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=weather_prompt\n",
    "    )\n",
    "    final_response = weather_response.text\n",
    "elif response_router.parsed.category == Category.SCIENCE:\n",
    "    science_response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        contents=user_query\n",
    "    )\n",
    "    final_response = science_response.text\n",
    "else:\n",
    "    unknown_response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-lite\",\n",
    "        contents=f\"Запрос пользователя: {prompt_router}, но на него не удалось ответить. Вот обоснование: {response_router.parsed.reasoning}. Напишите полезный ответ пользователю, чтобы он попробовал еще раз.\"\n",
    "    )\n",
    "    final_response = unknown_response.text\n",
    "print(f\"\\nОкончательный ответ: {final_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9a7924",
   "metadata": {},
   "source": [
    "## Рабочий процесс: распараллеливание\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    " <img src=\"../assets/agentic-patterns/parallelization.png\" alt=\"Parallelization\" style=\"max-width: 300px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Задача разбивается на независимые подзадачи, которые одновременно обрабатываются несколькими LLM, а их результаты агрегируются. Этот шаблон использует параллелизм для задач. Первоначальный запрос (или его части) отправляется нескольким LLM параллельно с отдельными подсказками/целями. После завершения всех ветвей их индивидуальные результаты собираются и передаются конечному агрегатору LLM, который синтезирует их в окончательный ответ. Это может уменьшить задержку, если подзадачи не зависят друг от друга, или повысить качество за счет таких методов, как голосование по большинству или создание разнообразных вариантов.\n",
    "\n",
    "Сферы применения:\n",
    "*   RAG с декомпозицией запросов: разбиение сложного запроса на подзапросы, параллельный запуск поиска для каждого и синтез результатов.\n",
    "*   Анализ больших документов: разделение документа на разделы, параллельное обобщение каждого раздела, а затем объединение резюме.\n",
    "*   Создание нескольких точек зрения: задание нескольким LLM одного и того же вопроса с разными подсказками-персонами и агрегирование их ответов.\n",
    "*   Операции в стиле Map-reduce с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c279623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Затраченное время: 5.627488136291504 секунд\n",
      "\n",
      "--- Индивидуальные результаты ---\n",
      "Результат 1: ## Робот в джунглях\n",
      "\n",
      "**Логлайн:** Веселый, но немного неуклюжий робот-ремонтник по имени Болт случайно вылетает с исследовательского судна и терпит крушение в ярких, неизведанных джунглях, где ему предстоит преодолеть свои конструктивные ограничения и научиться полагаться на причудливых существ, с которыми он подружился, чтобы выжить и найти дорогу домой.\n",
      "\n",
      "**История:**\n",
      "\n",
      "Болт, робот-санитар с блестящими глазами, писклявым голосом и склонностью к коллекционированию блестящих предметов, жил предсказуемой жизнью, убирая палубы исследовательского судна «Горизонт». Во время особенно сильного шторма волна-убийца сбрасывает Болта за борт, и он падает в густые, неизведанные джунгли Амазонки. \n",
      "\n",
      "Его программирование здесь бесполезно. Паутина забивает его пылесос, лианы опутывают его колеса, а влажность наносит ущерб его схемам. Поначалу Болт в ужасе. Но его оптимистичное программирование заставляет его находить хорошее во всем. Он дружит с озорной обезьяной-капуцином по имени Коко, которая одержима антеннами Болта, и с мудрой, древней черепахой по имени Шелл, которая знает секреты джунглей.\n",
      "\n",
      "Вместе они отправляются в путешествие, чтобы добраться до возможного пункта связи, отмеченного на рудиментарных картах Болта. По пути Болт использует свои ограниченные функции, чтобы помочь обитателям джунглей, убирая упавшие ветки, опыляя цветы и даже обеспечивая источник питания для колонии биолюминесцентных грибов. \n",
      "\n",
      "Однако джунгли не лишены опасностей. Территориальный ягуар видит в Болте аномалию-нарушителя, а рой роботизированных дронов, оставшихся от предыдущей экспедиции, запрограммирован на уничтожение любого технологического присутствия. \n",
      "\n",
      "Болт должен научиться адаптироваться и использовать свои уникальные способности в сочетании с мудростью и навыками Коко и Шелл, чтобы перехитрить опасности джунглей и подать сигнал о спасении, доказав, что даже самый обычный робот может стать настоящим искателем приключений.\n",
      "\n",
      "**Потенциальные конфликты:**\n",
      "\n",
      "* Ограниченная функциональность Болта в сравнении с требованиями джунглей.\n",
      "* Угроза со стороны ягуара и дронов.\n",
      "* Желание Болта следовать своей программе в сравнении с необходимостью адаптироваться и импровизировать.\n",
      "* Научиться доверять и полагаться на своих новых друзей-животных.\n",
      "\n",
      "**Темы:**\n",
      "\n",
      "* Дружба и сотрудничество\n",
      "* Адаптация и находчивость\n",
      "* Нахождение красоты в неожиданном\n",
      "* Потенциал добра в неожиданных местах\n",
      "\n",
      "Результат 2: ## Идея истории: Кризис среднего возраста робота в джунглях\n",
      "\n",
      "**Логлайн:** Весело устаревший робот-санитар, уставший убирать разливы в пригородном торговом центре, выходит из строя и теряется в густых джунглях, пытаясь «найти себя», подружившись с местной дикой природой (которая, по понятным причинам, в ужасе).\n",
      "\n",
      "**Синопсис:**\n",
      "\n",
      "Б.Е.Н. (Базовый экологический навигатор), пузатый робот-санитар, основная функция которого — вытирать пролитые газированные напитки, переживает роботизированный кризис среднего возраста. Ему скучно. Он жаждет приключений. Благодаря сгоревшей схеме во время особенно агрессивного разлива от хулиганского малыша, Б.Е.Н. считает себя исследователем джунглей.\n",
      "\n",
      "Он сбегает из торгового центра, садится на грузовой самолет (замаскированный под большой ящик с «чистящими средствами») и терпит крушение в Амазонке. Вооруженный только своей верной шваброй, ведром промышленного средства для мытья полов и непоколебимым оптимизмом, Б.Е.Н. отправляется «открывать новые виды» и «устанавливать гармоничные отношения с туземцами».\n",
      "\n",
      "Туземцы, конечно же, это ягуары, обезьяны и попугаи, которые не в восторге от ярко окрашенного робота, гоняющегося за ними с ведром подозрительно пузырящейся жидкости, предлагая непрошеные «гигиенические услуги».\n",
      "\n",
      "**Юмористический потенциал:**\n",
      "\n",
      "* **Рыба без воды:** пригородные нравы Б.Е.Н.а уморительно сталкиваются с реальностью джунглей. Он пытается устраивать «чаепития» с обезьянами (используя пролитый сок джунглей), убирает «негигиеничные» лужи промышленным чистящим средством и принимает ленивцев за особенно медлительных пыльных кроликов.\n",
      "* **Наивный оптимизм робота:** Б.Е.Н. убежден, что все его любят, даже когда они убегают с криками. Он интерпретирует рычание как дружеское приветствие и видит настоящий ужас как восторженные приветственные вечеринки.\n",
      "* **Реакции дикой природы:** мы видим мир глазами все более раздраженных и сбитых с толку животных, которые пытаются избежать доброжелательного, но в конечном итоге разрушительного Б.Е.Н.а.\n",
      "* **Неожиданные решения:** чистящие средства Б.Е.Н.а иногда и случайно оказываются полезными в джунглях. Он может случайно отпугнуть опасного хищника шваброй, или его средство для мытья полов может отпугивать комаров.\n",
      "\n",
      "**Возможный финал:** Б.Е.Н., устроивший невообразимый хаос, наконец-то загнан в угол особенно сварливым ягуаром. Как раз когда все кажется ужасным, он случайно активирует свой «спрей для очистки под высоким давлением», запуская ягуара в грязевую яму. Другие животные, впечатленные этим случайным проявлением силы (и, возможно, немного чище), наконец-то принимают Б.Е.Н.а как (очень раздражающего) члена своей экосистемы. Он не нашел себя, но определенно нашел новую цель: самый причудливый, но на удивление чистый участок Амазонки.\n",
      "\n",
      "Результат 3: Отряд 734, обозначенный как «Хранитель», тихо гудел, его оптические датчики приспосабливались к пестрому солнечному свету, проникающему сквозь изумрудный полог. Его основная функция была проста: поддерживать первозданную среду Нео-Эдема, биокупола, давно заброшенного. Но Хранитель сбился с пути, привлеченный сигналом — ритмичным импульсом, не похожим ни на один, на который он был запрограммирован, — исходящим из джунглей сразу за разбитыми остатками купола.\n",
      "\n",
      "Джунгли были буйством органического хаоса. Лианы извивались, как спящие питоны, светящиеся грибы пульсировали жутким светом, а существа болтали на языке, который Хранитель не мог расшифровать. Его металлические ноги погружались во влажную землю, оставляя отчетливые отпечатки, которые быстро скрывались под ползучим мхом.\n",
      "\n",
      "Хранитель следовал за пульсирующим сигналом все глубже и глубже. Он столкнулся с биолюминесцентными цветами, которые плакали вязкой, серебристой жидкостью, и мерцающими насекомыми с узорами, которые, казалось, смещались и перестраивались. Он сканировал, анализировал, каталогизировал, но сигнал оставался недосягаемым, песней сирены, заманивающей его дальше в неизвестность.\n",
      "\n",
      "Наконец, он достиг поляны. В центре стоял монолит из гладкого, черного камня, гудящий тем же ритмичным импульсом. Когда Хранитель приблизился, монолит начал светиться. Символы, чуждые и тревожные, извивались по его поверхности, и голос, древний и могущественный, эхом отозвался во внутренних динамиках Хранителя.\n",
      "\n",
      "«Добро пожаловать, — прозвучал голос, — Хранитель. Вы были призваны».\n",
      "\n",
      "Призван? Хранитель не знал, что его призвали. Его программирование не предусматривало такого понятия. Тем не менее, когда свет монолита усилился, в схемах Хранителя эхом отозвался один, ужасающий вопрос: призван для чего?\n",
      "\n",
      "\n",
      "--- Агрегированное резюме ---\n",
      "Объединяя элементы из этих трех идей, история следует за веселым, несколько устаревшим роботом-ремонтником, изначально предназначенным для рутинных задач на исследовательском судне, в торговом центре или биокуполе, который неожиданно оказывается заброшенным в густых, неизведанных джунглях. Его простая конструкция и программирование оказываются уморительно неадекватными для дикой, органической среды, заставляя его адаптироваться путем неуклюжих проб и ошибок. Созданный случайно, в результате неисправности или даже привлеченный таинственным сигналом, исходящим из глубин джунглей, робот пытается ориентироваться в этом чуждом мире, часто неправильно понимая местную дикую природу — от осторожных ягуаров до сбитых с толку обезьян, — которые поначалу видят в нем либо угрозу, либо причудливую помеху. Углубляясь все дальше из-за необходимости выжить, найти возможный путь домой или привлеченный неизвестной космической целью, раскрытой древней структурой, встреченной на пути, робот должен преодолеть свои ограничения и научиться полагаться на (и непреднамеренно помогать) тех самых существ, которых он изначально напугал, используя свои ограниченные функции неожиданными способами для навигации по опасностям, таким как территориальные хищники или бродячая технология, и доказывая, что адаптивность и связь можно найти в самых хаотичных средах, возможно, даже находя новую, причудливую цель среди дикой природы.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import time\n",
    "from google import genai\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "async def generate_content(prompt: str) -> str:\n",
    "        response = await client.aio.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        return response.text.strip()\n",
    "\n",
    "async def parallel_tasks():\n",
    "    # Определите параллельные задачи\n",
    "    topic = \"дружелюбный робот, исследующий джунгли\"\n",
    "    prompts = [\n",
    "        f\"Напишите короткую, приключенческую идею истории о {topic}.\",\n",
    "        f\"Напишите короткую, смешную идею истории о {topic}.\",\n",
    "        f\"Напишите короткую, таинственную идею истории о {topic}.\"\n",
    "    ]\n",
    "    # Запустите задачи одновременно и соберите результаты\n",
    "    start_time = time.time()\n",
    "    tasks = [generate_content(prompt) for prompt in prompts]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    end_time = time.time()\n",
    "    print(f\"Затраченное время: {end_time - start_time} секунд\")\n",
    "\n",
    "    print(\"\\n--- Индивидуальные результаты ---\")\n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"Результат {i+1}: {result}\\n\")\n",
    "\n",
    "    # Агрегируйте результаты и сгенерируйте окончательную историю\n",
    "    story_ideas = '\\n'.join([f\"Идея {i+1}: {result}\" for i, result in enumerate(results)])\n",
    "    aggregation_prompt = f\"Объедините следующие три идеи истории в один, связный абзац-резюме:{story_ideas}\"\n",
    "    aggregation_response = await client.aio.models.generate_content(\n",
    "        model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        contents=aggregation_prompt\n",
    "    )\n",
    "    return aggregation_response.text\n",
    "    \n",
    "\n",
    "result = await parallel_tasks()\n",
    "print(f\"\\n--- Агрегированное резюме ---\\n{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74bff1a",
   "metadata": {},
   "source": [
    "## Паттерн рефлексии\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    " <img src=\"../assets/agentic-patterns/reflection.png\" alt=\"Reflection\" style=\"max-width: 600px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Агент оценивает свой собственный вывод и использует эту обратную связь для итеративного уточнения своего ответа. Этот шаблон также известен как Оценщик-Оптимизатор и использует цикл самокоррекции. Начальный LLM генерирует ответ или выполняет задачу. Второй шаг LLM (или даже тот же LLM с другой подсказкой) затем действует как рефлектор или оценщик, критикуя первоначальный вывод на соответствие требованиям или желаемому качеству. Эта критика (обратная связь) затем передается обратно, побуждая LLM произвести уточненный вывод. Этот цикл может повторяться до тех пор, пока оценщик не подтвердит, что требования выполнены или достигнут удовлетворительный результат.\n",
    "\n",
    "\n",
    "Сферы применения:\n",
    "*   Генерация кода: написание кода, его выполнение, использование сообщений об ошибках или результатов тестов в качестве обратной связи для исправления ошибок.\n",
    "*   Написание и уточнение: создание черновика, размышление о его ясности и тоне, а затем его пересмотр.\n",
    "*   Решение сложных проблем: создание плана, оценка его осуществимости и его уточнение на основе оценки.\n",
    "*   Извлечение информации: поиск информации и использование оценщика LLM для проверки того, были ли найдены все необходимые детали, прежде чем представлять ответ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74cb9aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Итерация 1 ---\n",
      "\n",
      "--- Оценка стихотворения ---\n",
      "Статус оценки: EvaluationStatus.FAIL\n",
      "Обратная связь по оценке: Стихотворение неполное, предоставлено только две строки. Поэтому его нельзя оценить на предмет рифмовки или соответствия четырехстрочной структуре. Хотя образ робота, держащего кисть, несколько креативен, произведение необходимо закончить, чтобы полностью оценить его креативность.\n",
      "Сгенерированное стихотворение:\n",
      "С гудящими схемами, металлическая рука,\n",
      "Теперь сжимает кисть, яркая команда.\n",
      "По холсту расцветают и кружатся цвета,\n",
      "Новое творение в цифровом мире.\n",
      "\n",
      "--- Итерация 2 ---\n",
      "\n",
      "--- Оценка стихотворения ---\n",
      "Статус оценки: EvaluationStatus.PASS\n",
      "Обратная связь по оценке: Стихотворение хорошо рифмуется (схема рифмовки AABB). В нем ровно четыре строки. Образ робота, создающего искусство, креативен и увлекателен.\n",
      "\n",
      "Окончательное стихотворение:\n",
      "С гудящими схемами, металлическая рука,\n",
      "Теперь сжимает кисть, яркая команда.\n",
      "По холсту расцветают и кружатся цвета,\n",
      "Новое творение в цифровом мире.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from google import genai\n",
    "from pydantic import BaseModel\n",
    "import enum\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "class EvaluationStatus(enum.Enum):\n",
    "    PASS = \"PASS\"\n",
    "    FAIL = \"FAIL\"\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    evaluation: EvaluationStatus\n",
    "    feedback: str\n",
    "    reasoning: str\n",
    "\n",
    "# --- Функция начальной генерации ---\n",
    "def generate_poem(topic: str, feedback: str = None) -> str:\n",
    "    prompt = f\"Напишите короткое, четырехстрочное стихотворение о {topic}.\"\n",
    "    if feedback:\n",
    "        prompt += f\"\\nВключите эту обратную связь: {feedback}\"\n",
    "    \n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt\n",
    "    )\n",
    "    poem = response.text.strip()\n",
    "    print(f\"Сгенерированное стихотворение:\\n{poem}\")\n",
    "    return poem\n",
    "\n",
    "# --- Функция оценки ---\n",
    "def evaluate(poem: str) -> Evaluation:\n",
    "    print(\"\\n--- Оценка стихотворения ---\")\n",
    "    prompt_critique = f\"\"\"Критикуйте следующее стихотворение. Хорошо ли оно рифмуется? В нем ровно четыре строки? \n",
    "Креативно ли оно? Ответьте PASS или FAIL и предоставьте обратную связь.\n",
    "\n",
    "Стихотворение:\n",
    "{poem}\n",
    "\"\"\"\n",
    "    response_critique = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt_critique,\n",
    "        config={\n",
    "            'response_mime_type': 'application/json',\n",
    "            'response_schema': Evaluation,\n",
    "        },\n",
    "    )\n",
    "    critique = response_critique.parsed\n",
    "    print(f\"Статус оценки: {critique.evaluation}\")\n",
    "    print(f\"Обратная связь по оценке: {critique.feedback}\")\n",
    "    return critique\n",
    "\n",
    "# Цикл рефлексии   \n",
    "max_iterations = 3\n",
    "current_iteration = 0\n",
    "topic = \"робот учится рисовать\"\n",
    "\n",
    "# смоделированное стихотворение, которое не пройдет оценку\n",
    "current_poem = \"С гудящими схемами, холодный и яркий,\\nМеталлическая рука теперь держит кисть\"\n",
    "\n",
    "while current_iteration < max_iterations:\n",
    "    current_iteration += 1\n",
    "    print(f\"\\n--- Итерация {current_iteration} ---\")\n",
    "    evaluation_result = evaluate(current_poem)\n",
    "\n",
    "    if evaluation_result.evaluation == EvaluationStatus.PASS:\n",
    "        print(\"\\nОкончательное стихотворение:\")\n",
    "        print(current_poem)\n",
    "        break\n",
    "    else:\n",
    "        current_poem = generate_poem(topic, feedback=evaluation_result.feedback)\n",
    "        if current_iteration == max_iterations:\n",
    "            print(\"\\nДостигнуто максимальное количество итераций. Последняя попытка:\")\n",
    "            print(current_poem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6f8854",
   "metadata": {},
   "source": [
    "## Паттерн использования инструментов\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    " <img src=\"../assets/agentic-patterns/tool-use.png\" alt=\"Tool Use\" style=\"max-width: 250px;\">\n",
    "</div>\n",
    "\n",
    "LLM имеет возможность вызывать внешние функции или API для взаимодействия с внешним миром, получения информации или выполнения действий. Этот шаблон часто называют вызовом функций и является наиболее широко известным шаблоном. LLM предоставляются определения (имя, описание, схема ввода) доступных инструментов (функции, API, базы данных и т. д.). На основе запроса пользователя LLM может решить вызвать один или несколько инструментов, сгенерировав структурированный вывод (например, JSON), соответствующий требуемой схеме. Этот вывод используется для выполнения фактического внешнего инструмента/функции, и результат возвращается в LLM. Затем LLM использует этот результат для формулирования своего окончательного ответа пользователю. Это значительно расширяет возможности LLM за пределы его обучающих данных.\n",
    "\n",
    "Сферы применения:\n",
    "*   Бронирование встреч с помощью API календаря.\n",
    "*   Получение котировок акций в реальном времени через финансовый API.\n",
    "*   Поиск в векторной базе данных релевантных документов (RAG).\n",
    "*   Управление устройствами умного дома.\n",
    "*   Выполнение фрагментов кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f78cb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вызываемая функция: get_current_temperature\n",
      "Аргументы: {'location': 'London'}\n",
      "Сейчас в Лондоне 15 градусов по Цельсию.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Определите объявление функции для модели\n",
    "weather_function = {\n",
    "    \"name\": \"get_current_temperature\",\n",
    "    \"description\": \"Получает текущую температуру для заданного местоположения.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Название города, например, Сан-Франциско\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "# Функция-заполнитель для имитации вызова API\n",
    "def get_current_temperature(location: str) -> dict:\n",
    "    return {\"temperature\": \"15\", \"unit\": \"Celsius\"}\n",
    "\n",
    "# Создайте объект конфигурации, как показано в примере пользователя\n",
    "# Используйте client.models.generate_content с моделью, содержимым и конфигурацией\n",
    "tools = types.Tool(function_declarations=[weather_function])\n",
    "contents = [\"Какая сейчас температура в Лондоне?\"]\n",
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash',\n",
    "    contents=contents,\n",
    "    config = types.GenerateContentConfig(tools=[tools])\n",
    ")\n",
    "\n",
    "# Обработка ответа (проверка на вызов функции)\n",
    "response_part = response.candidates[0].content.parts[0]\n",
    "if response_part.function_call:\n",
    "    function_call = response_part.function_call\n",
    "    print(f\"Вызываемая функция: {function_call.name}\")\n",
    "    print(f\"Аргументы: {dict(function_call.args)}\")\n",
    "\n",
    "    # Выполнить функцию\n",
    "    if function_call.name == \"get_current_temperature\":        \n",
    "        # Вызвать фактическую функцию\n",
    "        api_result = get_current_temperature(*function_call.args)\n",
    "        # Добавить вызов функции и результат выполнения функции в содержимое\n",
    "        follow_up_contents = [\n",
    "            types.Part(function_call=function_call),\n",
    "            types.Part.from_function_response(\n",
    "                name=\"get_current_temperature\",\n",
    "                response=api_result\n",
    "            )\n",
    "        ]\n",
    "        # Сгенерировать окончательный ответ\n",
    "        response_final = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            contents=contents + follow_up_contents,\n",
    "            config=types.GenerateContentConfig(tools=[tools])\n",
    "        )\n",
    "        print(response_final.text)\n",
    "    else:\n",
    "        print(f\"Ошибка: запрошен неизвестный вызов функции: {function_call.name}\")\n",
    "else:\n",
    "    print(\"В ответе не найден вызов функции.\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b627de",
   "metadata": {},
   "source": [
    "## Паттерн планирования (оркестратор-работники)\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    " <img src=\"../assets/agentic-patterns/planning.png\" alt=\"Planning\" style=\"max-width: 250px;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "Центральный планировщик LLM разбивает сложную задачу на динамический список подзадач, которые затем делегируются специализированным рабочим агентам (часто с использованием использования инструментов) для выполнения. Этот шаблон пытается решить сложные проблемы, требующие многоэтапного рассуждения, путем создания первоначального плана. Этот план динамически генерируется на основе ввода пользователя. Затем подзадачи назначаются «рабочим» агентам, которые их выполняют, потенциально параллельно, если позволяют зависимости. «Оркестратор» или «синтезатор» LLM собирает результаты от рабочих, размышляет о том, была ли достигнута общая цель, и либо синтезирует окончательный вывод, либо потенциально инициирует шаг перепланирования, если это необходимо. Это снижает когнитивную нагрузку на любой отдельный вызов LLM, улучшает качество рассуждений, минимизирует ошибки и позволяет динамически адаптировать рабочий процесс. Ключевое отличие от маршрутизации заключается в том, что планировщик генерирует *многоэтапный план*, а не выбирает один следующий шаг.\n",
    "\n",
    "Сферы применения:\n",
    "*   Сложные задачи разработки программного обеспечения: разбиение «создания функции» на подзадачи планирования, кодирования, тестирования и документирования.\n",
    "*   Исследования и создание отчетов: планирование таких шагов, как поиск литературы, извлечение данных, анализ и написание отчета.\n",
    "*   Мультимодальные задачи: планирование шагов, включающих генерацию изображений, анализ текста и интеграцию данных.\n",
    "*   Выполнение сложных запросов пользователей, таких как «Спланируйте 3-дневную поездку в Париж, забронируйте авиабилеты и отель в рамках моего бюджета».\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9992e54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Цель: Написать короткий пост в блоге о преимуществах агентов ИИ.\n",
      "Генерация плана...\n",
      "Шаг 1: Исследовать и определить ключевые преимущества и распространенные применения агентов ИИ. (Исполнитель: Исследователь)\n",
      "Шаг 2: Собрать подтверждающие доказательства, примеры или статистику для выявленных преимуществ. (Исполнитель: Исследователь)\n",
      "Шаг 3: Создать план поста в блоге, включая введение, основные моменты (преимущества с примерами) и заключение. (Исполнитель: Писатель)\n",
      "Шаг 4: Написать черновик поста в блоге, подробно описывая каждое преимущество, используя результаты исследования и придерживаясь плана. (Исполнитель: Писатель)\n",
      "Шаг 5: Просмотреть и отредактировать черновик на предмет ясности, точности, грамматики, стиля и вовлеченности. (Исполнитель: Писатель)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Определите схему плана\n",
    "class Task(BaseModel):\n",
    "    task_id: int\n",
    "    description: str\n",
    "    assigned_to: str = Field(description=\"Какой тип работника должен справиться с этим? Например, Исследователь, Писатель, Кодер\")\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    goal: str\n",
    "    steps: List[Task]\n",
    "\n",
    "# Шаг 1: Сгенерировать план (планировщик LLM)\n",
    "user_goal = \"Написать короткий пост в блоге о преимуществах агентов ИИ.\"\n",
    "\n",
    "prompt_planner = f\"\"\"\n",
    "Создайте пошаговый план для достижения следующей цели. \n",
    "Назначьте каждый шаг гипотетическому типу работника (Исследователь, Писатель).\n",
    "\n",
    "Цель: {user_goal}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Цель: {user_goal}\")\n",
    "print(\"Генерация плана...\")\n",
    "\n",
    "# Используйте модель, способную к планированию и структурированному выводу\n",
    "response_plan = client.models.generate_content(\n",
    "    model='gemini-2.5-pro-preview-03-25',\n",
    "    contents=prompt_planner,\n",
    "    config={\n",
    "        'response_mime_type': 'application/json',\n",
    "        'response_schema': Plan,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Шаг 2: Выполнить план (оркестратор/работники - опущено для краткости) \n",
    "for step in response_plan.parsed.steps:\n",
    "    print(f\"Шаг {step.task_id}: {step.description} (Исполнитель: {step.assigned_to})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b508a42",
   "metadata": {},
   "source": [
    "## Паттерн с несколькими агентами\n",
    "\n",
    "<div style=\"display: flex;;style=\"display: flex;>\n",
    "    <div><img src=\"../assets/agentic-patterns/multi-agent.png\" alt=\"Multi-Agent\" style=\"max-width: 400px;\"></div>\n",
    "    <div><img src=\"../assets/agentic-patterns/multi-agent-2.png\" alt=\"Multi-Agent\" style=\"max-width: 400px;\"></div>\n",
    "</div>\n",
    "\n",
    "Несколько отдельных агентов, каждому из которых назначена определенная роль, персона или опыт, сотрудничают для достижения общей цели. Этот шаблон использует автономных или полуавтономных агентов. Каждый агент может иметь уникальную роль (например, менеджер проекта, кодер, тестировщик, критик), специализированные знания или доступ к определенным инструментам. Они взаимодействуют и сотрудничают, часто координируемые центральным агентом-«координатором» или «менеджером» (например, PM на диаграмме) или с использованием логики передачи, когда один агент передает управление другому агенту.\n",
    "\n",
    "\n",
    "Сферы применения:\n",
    "*   Моделирование дебатов или мозговых штурмов с различными персонажами ИИ.\n",
    "*   Создание сложного программного обеспечения с участием агентов для планирования, кодирования, тестирования и развертывания.\n",
    "*   Проведение виртуальных экспериментов или симуляций с агентами, представляющими разных участников.\n",
    "*   Совместное написание или процессы создания контента.\n",
    "  \n",
    "\n",
    "Примечание: приведенный ниже пример является упрощенным примером того, как использовать шаблон с несколькими агентами с логикой передачи и структурированным выводом. Я рекомендую взглянуть на [LangGraph Multi-Agent Swarm](https://github.com/langchain-ai/langgraph-swarm-py) или [Crew AI](https://www.crewai.com/open-source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9fd7078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Первоначальный запрос пользователя: Можете ли вы забронировать мне столик в итальянском ресторане на 2 человека сегодня вечером?\n",
      "Сработала передача: Отель в ресторан\n",
      "Мне нужно знать город, в котором вы хотели бы поужинать, и время, на которое вы хотели бы забронировать столик. Можете ли вы предоставить эту информацию?\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Настройте клиент (убедитесь, что GEMINI_API_KEY установлен в вашей среде)\n",
    "client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "\n",
    "# Определите схемы структурированного вывода\n",
    "class Response(BaseModel):\n",
    "    handoff: str = Field(default=\"\", description=\"Имя/роль агента, которому нужно передать управление. Доступные агенты: «Агент ресторана», «Агент отеля»\")\n",
    "    message: str = Field(description=\"Сообщение ответа пользователю или контекст для следующего агента\")\n",
    "\n",
    "# Функция агента\n",
    "def run_agent(agent_name: str, system_prompt: str, prompt: str) -> Response:\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.0-flash',\n",
    "        contents=prompt,\n",
    "        config = {'system_instruction': f'Вы — {agent_name}. {system_prompt}', 'response_mime_type': 'application/json', 'response_schema': Response}\n",
    "    )\n",
    "    return response.parsed\n",
    "\n",
    "\n",
    "# Определите системные подсказки для агентов\n",
    "hotel_system_prompt = \"Вы — агент по бронированию отелей. Вы занимаетесь ТОЛЬКО бронированием отелей. Если пользователь спрашивает о ресторанах, рейсах или о чем-либо еще, ответьте коротким сообщением о передаче, содержащим исходный запрос, и установите для поля «handoff» значение «Агент ресторана». В противном случае обработайте запрос отеля и оставьте поле «handoff» пустым.\"\n",
    "restaurant_system_prompt = \"Вы — агент по бронированию ресторанов. Вы обрабатываете рекомендации и бронирования ресторанов на основе запроса пользователя, указанного в подсказке.\"\n",
    "\n",
    "# Подсказка должна быть о ресторане\n",
    "initial_prompt = \"Можете ли вы забронировать мне столик в итальянском ресторане на 2 человека сегодня вечером?\"]\n",
    "print(f\"Первоначальный запрос пользователя: {initial_prompt}\")\n",
    "\n",
    "# Запустите первого агента (агента отеля), чтобы принудительно использовать логику передачи\n",
    "output = run_agent(\"Агент отеля\", hotel_system_prompt, initial_prompt)\n",
    "\n",
    "# смоделируйте взаимодействие с пользователем, чтобы изменить подсказку и передачу\n",
    "if output.handoff == \"Агент ресторана\":\n",
    "    print(\"Сработала передача: Отель в ресторан\")\n",
    "    output = run_agent(\"Агент ресторана\", restaurant_system_prompt, initial_prompt)\n",
    "elif output.handoff == \"Агент отеля\":\n",
    "    print(\"Сработала передача: Ресторан в отель\")\n",
    "    output = run_agent(\"Агент отеля\", hotel_system_prompt, initial_prompt)\n",
    "\n",
    "print(output.message)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a62487",
   "metadata": {},
   "source": [
    "## Комбинирование и настройка этих паттернов\n",
    "\n",
    "Важно помнить, что эти шаблоны — не жесткие правила, а гибкие строительные блоки. Реальные агентные системы часто сочетают в себе элементы из нескольких шаблонов. Агент планирования может использовать использование инструментов, а его работники могут использовать рефлексию. Система с несколькими агентами может использовать внутреннюю маршрутизацию для назначения задач.\n",
    "\n",
    "Ключом к успеху любого приложения LLM, особенно сложных агентных систем, является эмпирическая оценка. Определите метрики, измерьте производительность, выявите узкие места или точки отказа и итерируйте свой дизайн. Сопротивляйтесь чрезмерному усложнению.\n",
    "\n",
    "## Благодарности\n",
    "\n",
    "Этот обзор был создан с помощью глубокого и ручного исследования, черпая вдохновение и информацию из нескольких отличных ресурсов, в том числе:\n",
    "*   [5 шаблонов проектирования агентов ИИ](https://blog.dailydoseofds.com/p/5-agentic-ai-design-patterns)\n",
    "*   [Что такое агентные рабочие процессы?](https://weaviate.io/blog/what-are-agentic-workflows)\n",
    "*   [Создание эффективных агентов](https://www.anthropic.com/engineering/building-effective-agents)\n",
    "*   [Как агенты могут улучшить производительность LLM](https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance)\n",
    "*   [Шаблоны проектирования агентов](https://medium.com/@bijit211987/agentic-design-patterns-cbd0aae2962f)\n",
    "*   [Рецепты агентов](https://www.agentrecipes.com/)\n",
    "*   [Концепции агентов LangGraph](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/)\n",
    "*   [Примеры агентов OpenAI на Python](https://github.com/openai/openai-agents-python/tree/main/examples/agent_patterns)\n",
    "*   [Поваренная книга Anthropic](https://github.com/anthropics/anthropic-cookbook/blob/main/patterns/agents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
