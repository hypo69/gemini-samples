{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Gemini 2.0 with ADK (Agent Development Kit) and MCP (Model Context Protocol) Servers\n",
    "\n",
    "Agent Development Kit (ADK) is a new modular framework for developing and deploying AI agents. ADK makes it easy to get started with simple agents powered by Gemini models and Google AI tools while providing the control and structure needed for more complex agent architectures and orchestration.\n",
    "\n",
    "Gemini models can be used with MCP server using its native tool calling capabilities. MCP, or Model Context Protocol, is an open standard introduced by Anthropic designed to standardize how AI models like Gemini interact with external tools and data sources. Instead of requiring custom integrations for each tool, MCP provides a structured way for models to access context, such as functions (tools), data sources (resources), or pre-defined prompts. This allows AI agents to securely and efficiently connect with real-world systems and workflows.\n",
    "\n",
    "MCP server expose their tools via JSON schema definitions, which can be converted to Gemini compatible OpenAPI schema definitions. This allows you to easily use MCP server with Gemini models, below you will example on how to implement this. \n",
    "\n",
    "You can learn more about Google Search integration with Gemini here:\n",
    "- [https://ai.google.dev/gemini-api/docs/function-calling?lang=python](https://ai.google.dev/gemini-api/docs/function-calling?lang=python&example=weather)\n",
    "- [https://google.github.io/adk-docs/tools/mcp-tools/](https://google.github.io/adk-docs/tools/mcp-tools/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-adk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'],returning concatenated text result from text parts,check out the non text parts for full response from model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function call: {'location': 'Berlin, DE', 'date': '2025-04-15'}\n",
      "Function response: {'result': CallToolResult(meta=None, content=[TextContent(type='text', text='{\"2025-04-15T00:00\":14.1,\"2025-04-15T01:00\":13.8,\"2025-04-15T02:00\":13.4,\"2025-04-15T03:00\":13.1,\"2025-04-15T04:00\":12.6,\"2025-04-15T05:00\":12.1,\"2025-04-15T06:00\":12.9,\"2025-04-15T07:00\":14.4,\"2025-04-15T08:00\":17,\"2025-04-15T09:00\":19.4,\"2025-04-15T10:00\":20.3,\"2025-04-15T11:00\":20.7,\"2025-04-15T12:00\":21.1,\"2025-04-15T13:00\":20.9,\"2025-04-15T14:00\":20.1,\"2025-04-15T15:00\":19.3,\"2025-04-15T16:00\":18.9,\"2025-04-15T17:00\":18.3,\"2025-04-15T18:00\":17.7,\"2025-04-15T19:00\":16.8,\"2025-04-15T20:00\":16.1,\"2025-04-15T21:00\":15.5,\"2025-04-15T22:00\":14.9,\"2025-04-15T23:00\":14.4}', annotations=None)], isError=False)}\n",
      "OK. The weather in Berlin tomorrow, 2025-04-15, will be as follows: The temperature in Berlin will be between 12.1 and 21.1 degrees Celsius.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.genai import types\n",
    "from google.adk import Agent, Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import MCPToolset, StdioServerParameters\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "async def mcp_agent():\n",
    "        # --- Step 1: Connect to MCP Server and Get Tools ---\n",
    "        tools, exit_stack = await MCPToolset.from_server(\n",
    "            connection_params=StdioServerParameters(\n",
    "            command=\"npx\", \n",
    "            args=[\"-y\", \"@philschmid/weather-mcp\"], \n",
    "             # connection_params=SseServerParams(url=\"http://remote-server:port/path\", headers={...})\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # --- Step 2: Define the Agent ---\n",
    "        root_agent = Agent(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            name='weather_assistant',\n",
    "            instruction='Can read the weather in a specific city',\n",
    "            tools=tools, \n",
    "            \n",
    "        )\n",
    "\n",
    "        # --- Step 3: Setup Session, Runner, and Execute ---\n",
    "        # Session saves the conversation history and state\n",
    "        session_service = InMemorySessionService()\n",
    "        session = session_service.create_session(\n",
    "            state={}, app_name='weather_app', user_id='user_fs'\n",
    "        )\n",
    "        # Runner is responsible for executing the agent\n",
    "        runner = Runner(\n",
    "            app_name='weather_app',\n",
    "            agent=root_agent,\n",
    "            session_service=session_service,\n",
    "        )\n",
    "\n",
    "        # --- Step 4: Run the agent ---\n",
    "        prompt = \"What is the weather in Berlin tomorrow, 2025/04/15?\"\n",
    "        user_content = types.Content(role='user', parts=[types.Part(text=prompt)])\n",
    "\n",
    "        events_async = runner.run_async(\n",
    "            session_id=session.id, user_id=session.user_id, new_message=user_content\n",
    "        )\n",
    "\n",
    "        async for event in events_async:\n",
    "            if event.content.parts[0].function_call:\n",
    "                print(f\"Function call: {event.content.parts[0].function_call.args}\")\n",
    "            elif event.content.parts[0].function_response:\n",
    "                print(f\"Function response: {event.content.parts[0].function_response.response}\")\n",
    "            else:\n",
    "                print(event.content.parts[0].text)\n",
    "   \n",
    "\n",
    "        # --- 5: Cleanup MCP server connection ---\n",
    "        if exit_stack:\n",
    "            await exit_stack.aclose()\n",
    "\n",
    "await mcp_agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
